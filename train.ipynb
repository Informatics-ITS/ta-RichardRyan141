{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2610ac",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import monai\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import csv\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    Activations,\n",
    "    RandRotated,\n",
    "    RandScaleIntensityd,\n",
    "    RandShiftIntensityd,\n",
    ")\n",
    "\n",
    "from monai.networks.nets import UNETR\n",
    "from monai.metrics import DiceMetric, DiceHelper, HausdorffDistanceMetric\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6eb0af",
   "metadata": {},
   "source": [
    "# Variabel yang perlu diubah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc05f54",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Ukuran input model\n",
    "model_input_size = (128,128,128)\n",
    "\n",
    "# Jumlah patch yang diambil\n",
    "patch_num = 4\n",
    "\n",
    "# Ratio dice loss untuk perhitungan DiceCELoss\n",
    "dice_ratio = 0.6\n",
    "ce_ratio = 1.0 - dice_ratio\n",
    "\n",
    "# Tipe optimizer\n",
    "optim_type = \"SGD\"\n",
    "\n",
    "# CSV train-val \n",
    "train_csv = \"CSV/data_train.csv\"\n",
    "val_csv = \"CSV/data_val.csv\"\n",
    "\n",
    "# Apakah merupakan data tanpa reorientasi?\n",
    "is_resized = True\n",
    "resized_dir = \"resized_data\"\n",
    "reorient_dir = \"reoriented_data\"\n",
    "\n",
    "# Dataset cache rate\n",
    "cache_rate = 1.0\n",
    "\n",
    "# Batch size \n",
    "batch_size = 1\n",
    "\n",
    "# Model dir & checkpoint\n",
    "model_dir = \"results/Exp1/Reorient-50-50\"\n",
    "model_ckpt = \"\"\n",
    "\n",
    "# Simpan checkpoint model setiap ... epoch\n",
    "save_every = 25\n",
    "\n",
    "# Epoch mulai dan selesai\n",
    "start_epoch = 0\n",
    "end_epoch = 2500\n",
    "\n",
    "# Hasil terbaik saat validasi (ubah hanya jika melanjutkan training)\n",
    "dice_val_best = 0\n",
    "dice_val_best_epoch = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d525f8",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e22ca09",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        RandRotated(keys=[\"image\", \"label\"], range_x=30, range_y=30, range_z=30, prob=0.4, mode=[\"bilinear\", \"nearest\"]),\n",
    "        RandScaleIntensityd(keys=\"image\", factors=0.1, prob=0.3),\n",
    "        RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=0.3),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=model_input_size,\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=patch_num,\n",
    "            image_key=\"image\",\n",
    "            image_threshold=0,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),      \n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34f4a7c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = UNETR(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    img_size=model_input_size,\n",
    "    feature_size=16,\n",
    "    hidden_size=768,\n",
    "    mlp_dim=3072,\n",
    "    num_heads=12,\n",
    "    proj_type=\"perceptron\",\n",
    "    norm_name=\"instance\",\n",
    "    res_block=True,\n",
    "    dropout_rate=0.0,\n",
    ").to(device)\n",
    "\n",
    "loss_function = DiceCELoss(to_onehot_y=True, sigmoid=True, lambda_dice=0.6, lambda_ce=0.4)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "post_label = AsDiscrete(threshold=0.5)\n",
    "post_pred = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False, ignore_empty=True)\n",
    "hausdorff_metric = HausdorffDistanceMetric(include_background=True, reduction=\"mean\", get_not_nans=False, percentile=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05048bf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if(optim_type == \"Adam\"):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "elif(optim_type == \"Adagrad\"):\n",
    "    optimizer = torch.optim.Adagrad(model.parameters(), lr=1e-2, lr_decay=0, weight_decay=1e-5)\n",
    "elif(optim_type == \"Adadelta\"):\n",
    "    optimizer = torch.optim.Adadelta(model.parameters(), lr=1.0, rho=0.9, eps=1e-6, weight_decay=1e-5)\n",
    "elif(optim_type == \"SGD\"):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, weight_decay=1e-5, nesterov=True)\n",
    "elif(optim_type == \"RMSProp\"):\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-4, alpha=0.99, eps=1e-8, weight_decay=1e-5, momentum=0.9)\n",
    "else:\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa615df6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(train_csv)\n",
    "df_val = pd.read_csv(val_csv)\n",
    "\n",
    "if (is_resized):\n",
    "    df_train['TOF_pre'] = df_train['TOF_pre'].str.replace(reorient_dir, resized_dir, regex=False)\n",
    "    df_train['labels'] = df_train['labels'].str.replace(reorient_dir, resized_dir, regex=False)\n",
    "    df_val['TOF_pre'] = df_val['TOF_pre'].str.replace(reorient_dir, resized_dir, regex=False)\n",
    "    df_val['labels'] = df_val['labels'].str.replace(reorient_dir, resized_dir, regex=False)\n",
    "\n",
    "TOF_pre_train_path = df_train['TOF_pre']\n",
    "TOF_pre_val_path = df_val['TOF_pre']\n",
    "label_train_path = df_train['labels']\n",
    "label_val_path = df_val['labels']\n",
    "\n",
    "train_dict = [{\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(TOF_pre_train_path, label_train_path)]\n",
    "val_dict = [{\"image\": image_names, \"label\": label_names} for image_names, label_names in zip(TOF_pre_val_path, label_val_path)]\n",
    "\n",
    "train_ds = CacheDataset(data=train_dict, transform=train_transforms, cache_rate=cache_rate, num_workers=4)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "val_ds = CacheDataset(data=val_dict, transform=val_transforms, cache_rate=cache_rate, num_workers=4)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5513aa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "csv_file = os.path.join(model_dir, f\"loss_log.csv\")\n",
    "\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "if model_ckpt != \"\":\n",
    "    if os.path.exists(model_ckpt):\n",
    "        print(f\"Weights loaded from {model_ckpt}\")\n",
    "        model.load_state_dict(torch.load(model_ckpt))\n",
    "    else:\n",
    "        print(f\"Model checkpoint ({model_ckpt}) not found\")\n",
    "\n",
    "if (not(os.path.exists(csv_file))):\n",
    "    with open(csv_file, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"epoch\", \"train loss\", \"val mean dice\", \"val hausdorff\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1abe05",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dice_val_best = 0\n",
    "dice_val_best_epoch = 0\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "    time_start = datetime.now()\n",
    "    print(\"-\" * 10)\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        step += 1\n",
    "        x, y = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logit_map = model(x)\n",
    "        loss = loss_function(logit_map, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    epoch_loss /= step\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            val_inputs, val_labels = (batch[\"image\"].cuda(), batch[\"label\"].cuda())\n",
    "            val_outputs = sliding_window_inference(val_inputs, (128, 128, 128), 4, model)\n",
    "            val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
    "            val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
    "            dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "            hausdorff_metric(y_pred=val_outputs, y=val_labels)\n",
    "        mean_dice_val = dice_metric.aggregate().item()\n",
    "        mean_hausdorff_score = hausdorff_metric.aggregate().item()\n",
    "        dice_metric.reset()\n",
    "        hausdorff_metric.reset()\n",
    "\n",
    "    if mean_dice_val > dice_val_best:\n",
    "        dice_val_best = mean_dice_val\n",
    "        dice_val_best_epoch = epoch+1\n",
    "        torch.save(model.state_dict(), os.path.join(model_dir, f\"best_metric_model.pth\"))\n",
    "        print(\"saved new best metric model\")\n",
    "    print(\n",
    "        f\"best mean dice: {dice_val_best:.4f} \"\n",
    "        f\"at epoch: {dice_val_best_epoch}\"\n",
    "    )\n",
    "\n",
    "    with open(csv_file, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([epoch + 1, epoch_loss, mean_dice_val, mean_hausdorff_score])\n",
    "\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f} - Validation Dice: {mean_dice_val:.4f} Hausdorff: {mean_hausdorff_score:.4f} - Time taken: {datetime.now() - time_start}\")\n",
    "    if ((epoch+1) % save_every == 0):\n",
    "        torch.save(model.state_dict(), os.path.join(model_dir, f\"model_e{epoch+1}.pth\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f783220",
   "metadata": {},
   "source": [
    "Struktur akhir setelah training :  \n",
    "\n",
    "results/Exp1/  \n",
    "|-- Reorient-50-50/  \n",
    "|&nbsp;&nbsp;&nbsp;&nbsp;|-- best_metric_model.pth  \n",
    "|&nbsp;&nbsp;&nbsp;&nbsp;|-- loss_log.csv  \n",
    "|&nbsp;&nbsp;&nbsp;&nbsp;|-- model_e25.pth  \n",
    "|&nbsp;&nbsp;&nbsp;&nbsp;|-- model_e50.pth  \n",
    "|&nbsp;&nbsp;&nbsp;&nbsp;|...  \n",
    "|-- Resize-50-50/  \n",
    "|&nbsp;&nbsp;&nbsp;&nbsp;|-- best_metric_model.pth  \n",
    "|&nbsp;&nbsp;&nbsp;&nbsp;|-- loss_log.csv  \n",
    "|&nbsp;&nbsp;&nbsp;&nbsp;|-- model_e25.pth  \n",
    "|&nbsp;&nbsp;&nbsp;&nbsp;|-- model_e50.pth  \n",
    "|&nbsp;&nbsp;&nbsp;&nbsp;|...  \n",
    "..."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
