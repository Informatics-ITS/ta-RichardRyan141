{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279c8dea",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import torch\n",
    "import csv\n",
    "\n",
    "import monai\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import (\n",
    "\tAsDiscrete,\n",
    "\tEnsureChannelFirstd,\n",
    "\tCompose,\n",
    "\tCropForegroundd,\n",
    "\tLoadImaged,\n",
    "\tOrientationd,\n",
    "\tActivations,\n",
    "\tEnsureType,\n",
    "\tLoadImage,\n",
    "\tOrientation\n",
    ")\n",
    "\n",
    "from monai.networks.nets import UNETR\n",
    "from monai.metrics import DiceMetric, HausdorffDistanceMetric, compute_hausdorff_distance\n",
    "from monai.data import CacheDataset, DataLoader, decollate_batch\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import wilcoxon\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2080aad7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Model path\n",
    "model_path = \"results/Exp1/Reorient-50-50/best_metric_model.pth\"\n",
    "\n",
    "# Model input size\n",
    "model_input_size = (128,128,128)\n",
    "\n",
    "# Jumlah patch input\n",
    "patch_num = 4\n",
    "\n",
    "# Validation results dir\n",
    "output_dir = \"output/Reorient-50-50\"\n",
    "\n",
    "# Apakah merupakan data tanpa reorientasi?\n",
    "is_resized = True\n",
    "resized_dir = \"resized_data\"\n",
    "reorient_dir = \"reoriented_data\"\n",
    "\n",
    "# CSV split Validation\n",
    "val_csv = \"CSV/data_val.csv\"\n",
    "\n",
    "# CSV hasil skor dice & hausdorff\n",
    "dice_csv = \"dice_Exp1.csv\"\n",
    "hausdorff_csv = \"hd_Exp1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0560e8b2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = UNETR(\n",
    "\tin_channels=1,\n",
    "\tout_channels=1,\n",
    "\timg_size=(128, 128, 128),\n",
    "\tfeature_size=16,\n",
    "\thidden_size=768,\n",
    "\tmlp_dim=3072,\n",
    "\tnum_heads=12,\n",
    "\tproj_type=\"perceptron\",\n",
    "\tnorm_name=\"instance\",\n",
    "\tres_block=True,\n",
    "\tdropout_rate=0.0,\n",
    ").to(device)\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "post_label = AsDiscrete(threshold=0.5)\n",
    "post_pred = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "to_numpy = Compose([EnsureType(data_type=\"numpy\")])\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "hausdorff_metric = HausdorffDistanceMetric(include_background=True, reduction=\"mean\", get_not_nans=False, percentile=95)\n",
    "\n",
    "infer_transforms = Compose(\n",
    "\t[\n",
    "\t\tLoadImaged(keys=[\"image\", \"label\"]),\n",
    "\t\tEnsureChannelFirstd(keys=[\"image\", \"label\"]),      \n",
    "\t\tCropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "\t\tOrientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "\t]\n",
    ")\n",
    "\n",
    "if(not os.path.exists(dice_csv)):\n",
    "\twith open(dice_csv, 'w', newline='') as csv_file:\n",
    "\t\twriter = csv.writer(csv_file)\n",
    "\t\twriter.writerow(['dir', 'Normal', 'TTA_1', 'TTA_2', 'TTA_3', 'TTA_4', 'TTA_5'])\n",
    "\t\tfor dir in dirs:\n",
    "\t\t\twriter.writerow([dir, '', '', '', '', '', '', '', ''])\n",
    "\n",
    "if(not os.path.exists(hausdorff_csv)):\n",
    "\twith open(hausdorff_csv, 'w', newline='') as csv_file:\n",
    "\t\twriter = csv.writer(csv_file)\n",
    "\t\twriter.writerow(['dir', 'Normal', 'TTA_1', 'TTA_2', 'TTA_3', 'TTA_4', 'TTA_5'])\n",
    "\t\tfor dir in dirs:\n",
    "\t\t\twriter.writerow([dir, '', '', '', '', '', '', '', ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8661fd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_val = pd.read_csv(val_csv)\n",
    "\n",
    "if (is_resized):\n",
    "    df_val['TOF_pre'] = df_val['TOF_pre'].str.replace(reorient_dir, resized_dir, regex=False)\n",
    "    df_val['labels'] = df_val['labels'].str.replace(reorient_dir, resized_dir, regex=False)\n",
    "\n",
    "TOF_pre_val_path = df_val['TOF_pre']\n",
    "label_val_path = df_val['labels']\n",
    "dirs = df_val['case_id']\n",
    "\n",
    "val_dict = [{\"image\": image_names, \"label\": label_names} for image_names, label_names in zip(TOF_pre_val_path, label_val_path)]\n",
    "val_ds = CacheDataset(data=val_dict, transform=infer_transforms, cache_rate=1.0, num_workers=4)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=4)\n",
    "\n",
    "eval_dict = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "\tfor i, val_data in enumerate(val_loader):\n",
    "\t\tdir = dirs[i]\n",
    "\t\tval_outputs = sliding_window_inference(val_data[\"image\"].to(device), model_input_size, patch_num, model, progress=True)\n",
    "\t\tval_outputs = [post_pred(j) for j in decollate_batch(val_outputs)]\n",
    "\t\tval_labels = [post_label(i) for i in decollate_batch(val_data[\"label\"].to(device))]\n",
    "\t\tdice_metric(y_pred=val_outputs, y=val_labels)\n",
    "\t\thausdorff_metric(y_pred=val_outputs, y=val_labels)\n",
    "\t\tfor j, output in enumerate(val_outputs):\n",
    "\t\t\toutput_np = to_numpy(output).squeeze(0)\n",
    "\t\t\tnib_image = nib.Nifti1Image(output_np, affine=np.eye(4))\n",
    "\t\t\t\n",
    "\t\t\toutput_filename = f\"{dir}_infer.nii.gz\"\n",
    "\t\t\toutput_filepath = os.path.join(output_dir, dir, output_filename)\n",
    "\t\t\t\n",
    "\t\t\tnib.save(nib_image, output_filepath)\n",
    "\t\tdice_score = dice_metric.aggregate().item()\n",
    "\t\thausdorff_score = hausdorff_metric.aggregate().item()\n",
    "\t\tdice_metric.reset()\n",
    "\t\thausdorff_metric.reset()\n",
    "\t\tprint(f\"Dir: {dir}. Dice Metric: {dice_score:.2f}\\tHausdorrf: {hausdorff_score:.2f}\\t{i+1}/{len(dirs)}\")\n",
    "\n",
    "\t\teval_dict[dir] = [dice_score, hausdorff_score]\n",
    "\n",
    "dice_col = os.path.basename(output_dir)\n",
    "haus_col = dice_col\n",
    "\n",
    "with open(dice_csv, 'r', newline='') as file:\n",
    "\trows = list(csv.reader(file))\n",
    "\n",
    "header = rows[0]\n",
    "if dice_col not in header:\n",
    "\theader.append(dice_col)\n",
    "\n",
    "col_index = header.index(dice_col)\n",
    "new_rows = [header]\n",
    "\n",
    "for row in rows[1:]:\n",
    "\tdir_name = row[0]\n",
    "\tscore = eval_dict.get(dir_name, [None])[0]\n",
    "\twhile len(row) < len(header):\n",
    "\t\trow.append('')\n",
    "\tif score is not None and row[col_index] == '':\n",
    "\t\trow[col_index] = f\"{score:.4f}\"\n",
    "\tnew_rows.append(row)\n",
    "\n",
    "with open(dice_csv, 'w', newline='') as file:\n",
    "\twriter = csv.writer(file)\n",
    "\twriter.writerows(new_rows)\n",
    "\n",
    "with open(hausdorff_csv, 'r', newline='') as file:\n",
    "\trows = list(csv.reader(file))\n",
    "\n",
    "header = rows[0]\n",
    "if haus_col not in header:\n",
    "\theader.append(haus_col)\n",
    "\n",
    "haus_index = header.index(haus_col)\n",
    "new_rows = [header]\n",
    "\n",
    "for row in rows[1:]:\n",
    "\tdir_name = row[0]\n",
    "\tscore = eval_dict.get(dir_name, [None, None])[1]\n",
    "\twhile len(row) < len(header):\n",
    "\t\trow.append('')\n",
    "\tif score is not None and row[haus_index] == '':\n",
    "\t\trow[haus_index] = f\"{score:.4f}\"\n",
    "\tnew_rows.append(row)\n",
    "\n",
    "with open(hausdorff_csv, 'w', newline='') as file:\n",
    "\twriter = csv.writer(file)\n",
    "\twriter.writerows(new_rows)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
